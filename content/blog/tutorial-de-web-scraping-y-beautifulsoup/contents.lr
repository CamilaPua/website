title: Tutorial: Web Scraping y BeautifulSoup
---
author: javier-daza
---
body:

Siempre tuve en mis favoritos del navegador el tutorial de dataquest <span style="font-style: italic;font-size: 1.3rem;">www.dataquest.io/blog/web-scraping-beautifulsoup/</span>, pero desde hace un tiempo para acá, bajaron dicho artículo de su página web. El propósito de este artículo es rescatar ese contenido y, de paso, traducirlo al español.

¡Empecemos!

Para obtener datos para proyectos de ciencia de datos, a menudo confiará en bases de datos [SQL](https://es.wikipedia.org/wiki/SQL) y [NoSQL](https://es.wikipedia.org/wiki/NoSQL), [API](https://es.wikipedia.org/wiki/API) o conjuntos de datos en formato CSV listos para usar.

El problema es que no siempre puede encontrar un conjunto de datos sobre un tema específico, las bases de datos no se mantienen actualizadas y las API son costosas o tienen límites de uso.

Sin embargo, si los datos que está buscando están en una página web, entonces la solución a todos estos problemas es el **web scraping.**

En este tutorial, aprenderemos a raspar varias páginas web con Python usando [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/) y [requests](https://docs.python-requests.org/en/latest/). Luego realizaremos un análisis simple usando [pandas](https://pandas.pydata.org/pandas-docs/stable/index.html) y [matplotlib](https://matplotlib.org/).

Para seguir este artículo necesitas tener:
- Una comprensión básica de HTML.
- Una buena comprensión de los conceptos básicos de Python.
- Una idea aproximada de qué es el web scraping.


## Scraping de datos para más de 2000 películas


Queremos analizar las distribuciones de las clasificaciones de películas de [IMDB](https://www.imdb.com/) y [Metacritic](https://www.metacritic.com/) para ver si encontramos algo interesante. Para hacer esto, primero recopilaremos datos de más de 2000 películas.

<span style="display: block;font-weight: 800;font-size: 1.7rem;font-style: italic;margin: 2rem 0;">
    Es fundamental identificar el objetivo de nuestro scraping desde el principio.
</span>

Escribir un script de scraping puede llevar mucho tiempo, especialmente si queremos scrapear más de una página web. Queremos evitar pasar horas escribiendo un script que extrae datos que en realidad no necesitaremos.

## Determinando qué páginas vamos a scrapear

Una vez que hemos establecido nuestro objetivo, debemos identificar un conjunto eficiente de páginas para scrapear.

Queremos encontrar una combinación de páginas que requiera un número relativamente pequeño de solicitudes. Una solicitud (*request* en inglés) es lo que sucede cada vez que accedemos a una página web. Nosotros 'solicitamos' el contenido de una página del servidor. Cuantas más solicitudes hagamos, más tiempo necesitará ejecutarse nuestro script y mayor será la sobrecarga en el servidor.

Una forma de obtener todos los datos que necesitamos es compilar una lista de nombres de películas y usarla para acceder a la página web de cada película en los sitios web de IMDB y Metacritic.


*----- GIF -------*

Como queremos obtener más de 2000 calificaciones tanto de IMDB como de Metacritic, tendremos que realizar al menos 4000 solicitudes. Si hacemos una solicitud por segundo, nuestro script necesitará un poco más de una hora para realizar 4000 solicitudes. Por ello, merece la pena intentar identificar formas más eficientes de obtener nuestros datos.

Si exploramos el sitio web de IMDB, podemos descubrir una forma de reducir a la mitad el número de solicitudes. Las puntuaciones de Metacritic se muestran en la página de películas de IMDB, por lo que podemos eliminar ambas clasificaciones con una sola solicitud:


*----- Imagen -------*

Si investigamos más a fondo el sitio de IMDB, podemos descubrir la página que se muestra a continuación. Contiene todos los datos que necesitamos para 50 películas. Dado nuestro objetivo, esto significa que solo tendremos que hacer unas 40 solicitudes, que es 100 veces menos que nuestra primera opción. Exploremos más esta última opción.


*----- Imagen -------*


## Identificando la estructura de la URL


Nuestro desafío ahora es asegurarnos de que entendemos la lógica de la URL a medida que cambian las páginas que queremos scrapear. Si no podemos entender esta lógica lo suficiente como para poder implementarla en el código, llegaremos a un callejón sin salida.

Si accede a la página de [búsqueda avanzada](https://www.imdb.com/search/) de IMDB, puede buscar películas por [año](https://www.imdb.com/search/title/#releasedate):

*----- Imagen -------*

En el campo "Release Date", busquemos por fechas de 2022-01-01 a 2022-12-31. Luego, al final de la página le damos click al botón de buscar. En la siguiente página ordenamos las películas por número de votos y le damos click al botón de siguiente, al final de la página final. Así llegaremos a esta página web, que tiene esta URL:

<span>https://www.imdb.com/search/title/?release_date=2022-01-01,2022-12-31&sort=num_votes,asc&start=51&ref_=adv_nxt</span>


*----- Imagen -------*

En la imagen de arriba, puedes ver que la URL tiene varios parámetros después del signo de interrogación:

- `release_date`: muestra solo las películas estrenadas en un año específico.
- `sort`: Ordena las películas en la página. `sort=num_votes,desc se traduce en ordenar por número de votos en orden descendente.
- `start`: especifica el número de inicio de las páginas a listar.
- `ref_`: Nos lleva a la página siguiente o anterior. La referencia es la página en la que nos encontramos actualmente. `adv_nxt` y `adv_prv` son dos valores posibles. Se traducen para avanzar a la página siguiente y avanzar a la página anterior, respectivamente.


Si navega por esas páginas y observa la URL, notará que solo cambian los valores de los parámetros. Esto significa que podemos escribir un script para que coincida con la lógica de los cambios y hacer muchas menos solicitudes para escrapear nuestros datos.

Comencemos a escribir el script solicitando el contenido de esta única página web:

<span>https://www.imdb.com/search/title/?release_date=2022&count=250</span>
<span>https://www.imdb.com/search/title?release_date=2017&sort=num_votes,desc&page=1</span>


En el primer bloque de código vamos a:

- Instalar `requests`

```bash
pip install requests
```
- Importar la función `get()` desde el módulo de `requests`.
- Asignar la dirección de la página web a una variable llamada `url`.
- Solicitar al servidor el contenido de la página web utilizando `get()` y almacenar la respuesta del servidor en la variable `respuesta`.
- Imprima una pequeña parte del contenido de la `respuesta` accediendo a su atributo `.text` (`respuesta` ahora es un objeto `Response`).


```python
from requests import get

url = 'https://www.imdb.com/search/title/?release_date=2022&count=250'

respuesta = get(url)

if respuesta.status_code == 200:
    print(respuesta.text[:500])
```

La respuesta que se obtiene:

```html
<!DOCTYPE html>
<html
    xmlns:og="http://ogp.me/ns#"
    xmlns:fb="http://www.facebook.com/2008/fbml">
    <head>
         

        <meta charset="utf-8">




        <script type="text/javascript">var IMDbTimer={starttime: new Date().getTime(),pt:'java'};</script>

<script>
    if (typeof uet == 'function') {
      uet("bb", "LoadTitle", {wb: 1});
    }
</script>
  <script>(function(t){ (t.events = t.events || {})["csm_head_pre_title"] = new Date().getTime(); })(IMDbTimer);</script>
   
```

## Comprendiendo la estructura HTML de una sola página

Como puede ver en la primera línea de `respuesta.text`, el servidor nos envió un documento HTML. Este documento describe la estructura general de esa página web, junto con su contenido específico (que es lo que hace que esa página en particular sea única).

Todas las páginas que queremos escrapear tienen la misma estructura general. Esto implica que también tienen la misma estructura general de HTML. Entonces, para escribir nuestro script, bastará con comprender la estructura HTML de una sola página. Para hacer eso, usaremos **las herramientas de desarrollo del navegador** (Developer Tools en inglés).

Si usa [Chrome](https://developer.chrome.com/devtools), haga clic con el botón derecho en un elemento de la página web que le interese y luego haga clic en *Inspeccionar*. Esto lo llevará directamente a la línea HTML que corresponde a ese elemento:

*----- Imagen -------*

También puede hacer esto con [Firefox](https://developer.mozilla.org/es/docs/Learn/Common_questions/Tools_and_setup/What_are_browser_developer_tools) y [Safari](https://developer.apple.com/safari/tools/) DevTools.

Tenga en cuenta que toda la información de cada película, incluido el póster, está contenida en una etiqueta `div`.


*----- Imagen -------*


Hay muchas líneas HTML anidadas dentro de cada etiqueta `div`. Puede explorarlos haciendo clic en esas pequeñas flechas grises a la izquierda de las líneas HTML correspondientes a cada `div`. Dentro de estas etiquetas anidadas encontraremos la información que necesitamos, como la calificación de una película.


*----- Imagen -------*

Se muestran 50 películas por página, por lo que debe haber un contenedor `div` para cada una. Extraigamos todos estos 50 contenedores mediante el análisis gramatical (*parsing* en inglés)del documento HTML de nuestra solicitud anterior.

## Usando BeautifulSoup para analizar el contenido HTML

Para analizar nuestro documento HTML y extraer los contenedores de 50 `div, usaremos un módulo de Python llamado [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/), el módulo de web scraping más común para Python.

En el siguiente bloque de código vamos a:

- Instalar `BeautifulSoup`.
- Importar el creador de la clase `BeautifulSoup` del paquete `bs4`.
- *Parsear* `respuesta.text` al crear un objeto `BeautifulSoup` y asignar este objeto a `sopa_html`. El argumento `'html.parser'` indica que queremos realizar el análisis utilizando el [analizador HTML integrado de Python](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#specifying-the-parser-to-use).


```bash
pip install beautifulsoup4
```

```python
from bs4 import BeautifulSoup
sopa_html = BeautifulSoup(respuesta.text, 'html.parser')
type(sopa_html)
```

Esto imprime que nuestra sopa es un objeto de tipo:

```bash
<class 'bs4.BeautifulSoup'>
```

Antes de extraer los 50 contenedores `div`, debemos averiguar qué los distingue de otros elementos `div` en esa página. A menudo, la marca distintiva reside en el [atributo](https://www.w3schools.com/Tags/att_global_class.asp) de `class`. Si inspecciona las líneas HTML de los contenedores de interés, notará que el atributo de `class` tiene dos valores:

- `lister-item`
- `mode-advanced`.

Esta combinación es exclusiva de estos contenedores `div`. Podemos ver que es cierto haciendo una búsqueda rápida con `(Ctrl + F)`. Tenemos 50 contenedores de este tipo, por lo que esperamos ver solo 50 coincidencias:

*----- Imagen -------*

Ahora usemos el método `find_all()` para extraer todos los contenedores `div` que tienen un atributo de clase de tipo `lister-item mode-advanced`:

```python
contenedores_pelicula = sopa_html.find_all('div', class_ = 'lister-item mode-advanced')
print('Contenedores de la película:', type(contenedores_pelicula))
print('Longitud:', len(contenedores_pelicula))
```

Lo cual imprime

```bash
Contenedores de la película: <class 'bs4.element.ResultSet'>
Longitud: 250
```

`find_all` devolvió un objeto tipo `ResultSet` que contiene una lista de los 250 divs que nos interesan.

Ahora solo seleccionaremos el primer contenedor y, por turno, extraeremos cada elemento que nos interesa:
- El nombre de la pelicula
- El año del estreno de la película
- La calificación de IMDB
- El Metascore
- El número de votos

*----- Imagen -------*

## Extraer los datos de una sola película

Podemos acceder al primer contenedor, que contiene información sobre una sola película, usando la notación de lista en `contenedores_pelicula`.

```python
primera_pelicula = contenedores_pelicula[0]
print(primera_pelicula)
```

*----- HTML de respuesta -------*

Esto nos regresa un HTML bastante largo, por lo que para hayar cada elemento, necesitaremos usar el inspector de elementos del navegador.


### El nombre de la pelicula

Comenzamos con el nombre de la película y localizamos su línea HTML correspondiente usando el inspector de elementos. Puede ver que el nombre está contenido dentro de una etiqueta de anclaje (`<a>`). Esta etiqueta está anidada dentro de una etiqueta de encabezado (`<h3>`). La etiqueta `<h3>` está anidada dentro de una etiqueta `<div>`. Este `<div>` es el tercero de los divs anidados en el contenedor de la primera película. Nosotros ya almacenamos el contenido de este contenedor en la variable `primera_pelicula`.

*----- Imagen -------*

`primera_pelicula` es un objeto `Tag` y las diversas etiquetas HTML que contiene se almacenan como sus atributos. Podemos acceder a ellos tal como accederíamos a cualquier atributo de un objeto Python. Sin embargo, usar un nombre de etiqueta como atributo solo seleccionará la primera etiqueta con ese nombre. Si ejecutamos `primera_pelicula.div`, solo obtenemos el contenido de la primera etiqueta `div`:


```bash
print(primera_pelicula.div)
```

```html
<div class="lister-top-right">
<div class="ribbonize" data-caller="filmosearch" data-tconst="tt14452776"></div>
</div>
```
Accediendo a la primera etiqueta de anclaje (`<a>`) no nos lleva al nombre de la película. El primer `<a>` está en algún lugar dentro del segundo div:

```bash
print(primera_pelicula.a)
```

```html
<a href="/title/tt14452776/"> <img alt="The Bear" class="loadlate" data-tconst="tt14452776" height="98" loadlate="https://m.media-amazon.com/images/M/MV5BYmM4MjBkNGMtZjE5Zi00ZDMwLWE5MjYtN2M0MTM2YTQ2MmNlXkEyXkFqcGdeQXVyMjkwOTAyMDU@._V1_UX67_CR0,0,67,98_AL_.jpg" src="https://m.media-amazon.com/images/S/sash/4FyxwxECzL-U1J8.png" width="67"/>
</a>
```

Sin embargo, accediendo a la primera etiqueta `<h3>` nos acerca mucho:

```bash
print(primera_pelicula.h3)
```

```html
<h3 class="lister-item-header">
<span class="lister-item-index unbold text-primary">1.</span>
<a href="/title/tt14452776/">The Bear</a>
<span class="lister-item-year text-muted unbold">(2022– )</span>
</h3>
```

Desde aquí, podemos usar la notación de atributos para acceder al primer `<a>` dentro de la etiqueta `<h3>`:


```bash
print(primera_pelicula.h3.a)
```

```html
<a href="/title/tt14452776/">The Bear</a>
```

Ahora es sólo cuestión de acceder al texto desde esa etiqueta `<a>:


```python
primer_nombre = primera_pelicula.h3.a.text
print(primer_nombre)
```

```bash
'The Bear'
```

### El año del estreno de la película
Este dato está en una etiqueta `<span>` que se encuentra debajo de la etiqueta `<a>` que contiene el nombre.

*----- Imagen -------*

La notación de puntos solo accederá al primer elemento `span`. Buscaremos por la marca distintiva del segundo `<span>`. Usaremos el método `find()` que es casi igual que `find_all()`, excepto que solo devuelve la primera coincidencia. De hecho, `find()` es equivalente a `find_all(limit = 1)`. El argumento `limit` limita la salida a la primera coincidencia.

La marca distintiva consiste en los valores `lister-item-year text-muted unbold` asignados al atributo `class`. Entonces buscamos el primer `<span>` con estos valores dentro de la etiqueta `<h3>`:


```python
primer_año = primera_pelicula.h3.find('span', class_ = 'lister-item-year text-muted unbold')
print(primer_año)
```

```bash
<span class="lister-item-year text-muted unbold">(2022– )</span>
```

Desde aquí, simplemente accedemos al texto usando notación de atributos:

```python
primer_año = primer_año.text
print(primer_año)
```

```bash
'(2022– )'
```

Podríamos limpiar fácilmente esa salida y convertirla a un número entero. Pero si exploras más páginas, notarás que para algunas películas el año toma valores impredecibles como (2017)(I) o (2015)(V). Es más eficiente hacer la limpieza después del scrapeado, cuando conoceremos todos los valores del año.


### La calificación de IMDB
Ahora nos centramos en extraer la calificación IMDB de la primera película.

Hay un par de formas de hacerlo, pero primero probaremos la más sencilla. Si inspecciona la calificación de IMDB usando DevTools, notará que la calificación está contenida dentro de una etiqueta `<strong>`.

*----- Imagen -------*

Usemos notación de atributos y esperemos que el primer `<strong>` también sea el que contenga la calificación.

```python
print(primera_pelicula.strong)
```

```html
<strong>8.5</strong>
```

¡Excelente! Accederemos al texto, lo convertiremos al tipo `float` y lo asignaremos a la variable `primer_imdb`:

```python
primer_imdb = float(primera_pelicula.strong.text)
print(primer_imdb)
```

```bash
8.5
```


### El Metascore

Si inspeccionamos el Metascore usando inspectod de elementos, notaremos que podemos encontrarlo dentro de una etiqueta `span`.

*----- Imagen -------*

La notación de atributos claramente no es una solución. Hay muchas etiquetas `<span>` antes de eso. Puedes ver una justo encima de la etiqueta `<strong>`. Será mejor que utilicemos los valores distintivos del atributo `class` (`metascore favorable`).

*Tenga en cuenta que si copia y pega esos valores de la pestaña del inspector de elemebtos, habrá dos caracteres de espacio en blanco entre `metascore` y `favorable`. Asegúrese de que solo haya un carácter de espacio en blanco cuando pase los valores como argumentos al parámetro `class_`. De lo contrario, `find()` no encontrará nada.*


```python
primer_mscore = primera_pelicula.find('span', class_ = 'metascore favorable')
primer_mscore = int(primer_mscore.text)
print(primer_mscore)
```

```bash
8.5
```

No todas las películas tienen puntuación. Más adelante abordaremos ese asunto.

Por ahora veamos que el valor `favorable` indica un Metascore alto y establece el color de fondo de la calificación en verde. Los otros dos valores posibles son `unfavorable` y mixed`. Sin embargo, lo que es específico de todas las calificaciones de Metascore es solo el valor de `metascore`. Este es el que usaremos cuando escribamos el script para toda la página.


### El número de votos
El número de votos está contenido en una etiqueta `<span>`. Su signo distintivo es un atributo del `name` con el valor `nv`.

*----- Imagen -------*

El atributo de `name` es diferente del atributo de `class`. Usando BeautifulSoup podemos acceder a elementos por cualquier atributo. Las funciones `find()` y `find_all()` tienen un parámetro llamado `attrs`. A esto podemos pasarle los atributos y valores que estamos buscando como diccionario:


```python
primeros_votos = primera_pelicula.find('span', attrs = {'name':'nv'})
print(primeros_votos)
```

```html
<span data-value="23878" name="nv">23,878</span>
```

Podríamos usar la notación `.text` para acceder al contenido de la etiqueta `<span>`. Sin embargo, sería mejor si accediéramos al valor del atributo de `data-value`. De esta manera podemos convertir el dato extraído a un `int` sin tener que eliminar una coma.

Puedes tratar un objeto `Tag` como un diccionario. Los atributos HTML son las claves del diccionario. Los valores de los atributos HTML son los valores de las claves del diccionario. Así es como podemos acceder al valor del atributo `data-value`:

```python
print(primeros_votos['data-value'])
```

```bash
23878
```

Convirtamos ese valor a un número entero y asignémoslo a `primeros_votos`:

```python
primeros_votos = int(primeros_votos['data-value'])
```

¡Eso es todo! Ahora estamos en condiciones de escribir fácilmente un script para extraer una sola página.

## El script para una sola página.
Antes de reconstruir lo que hemos hecho hasta ahora, debemos asegurarnos de extraer los datos solo de los contenedores que tienen Metascore.

*----- Imagen -------*

Necesitamos agregar una condición para omitir películas sin Metascore.

Usando el inspector de elementos nuevamente, vemos que la sección Metascore está contenida dentro de una etiqueta `<div>`. El atributo `class` tiene dos valores:

- `inline-block `
- `ratings-metascore`. 

El distintivo es claramente el `ratings-metascore`.


*----- Imagen -------*


Podemos usar `find()` para buscar en cada contenedor de película un div que tenga esa marca distintiva. Cuando `find()` no encuentra nada, devuelve un objeto `None`. Podemos usar este resultado en una declaración `if` para controlar si una película se scrapea.

Busquemos en la página web un contenedor de películas que no tenga Metascore y veamos qué devuelve `find()`.

*Importante: cuando ejecuté el siguiente código, el primer contenedor no tenía Metascore. Sin embargo, este es un objetivo cambiante, porque el número de votos cambia constantemente para cada película. Para obtener los mismos resultados que obtuve en la siguiente celda de código demostrativo, debe buscar un contenedor que no tenga un Metascore en el momento en que ejecuta el código.*


```python
puntaje_mscore_cero = contenedores_pelicula[0].find('div', class_ = 'ratings-metascore')
print(type(puntaje_mscore_cero))
```

```bash
<class 'NoneType'>
```

Ahora juntemos el código anterior y comprimámoslo tanto como sea posible, pero sólo en la medida en que sea fácilmente legible. En el siguiente bloque de código:

- Declare algunas variables de `lista` para tener algo en qué almacenar los datos extraídos.
- Recorra cada contenedor en `contenedores_pelicula` (la variable que contiene los 50 contenedores de películas).
- Extraiga los  datos de interés solo si el contenedor tiene un Metascore.
- Instalar el paquete de Python [Pandas](https://pandas.pydata.org/pandas-docs/stable/)

```bash
pip install pandas
```

```python
# Listas para guardar los datos scrapeados
nombres = []
años = []
calificaciones_imdb = []
metascores = []
votos = []

# Extraer dato de un contenedor de pelicula individual
for contenedor in contenedores_pelicula:
# Si la película tiene Metascore, entonces extrae:
    if contenedor.find('div', class_ = 'ratings-metascore') is not None:
        # El nombre
        nombre = contenedor.h3.a.text
        nombres.append(nombre)
        # El año
        año = contenedor.h3.find('span', class_ = 'lister-item-year').text
        años.append(año)
        # La calificación IMDB
        imdb = float(contenedor.strong.text)
        calificaciones_imdb.append(imdb)
        # El Metascore
        m_score = contenedor.find('span', class_ = 'metascore').text
        metascores.append(int(m_score))
        # El número de votos
        voto = contenedor.find('span', attrs = {'name':'nv'})['data-value']
        votos.append(int(voto))
```

Revisemos los datos recopilados hasta ahora. Pandas nos facilitará ver si hemos recopilado nuestros datos correctamente.



```python
import pandas as pd
test_df = pd.DataFrame({'película': nombres,
    'año': año,
    'imdb': calificaciones_imdb,
    'metascore': metascores,
    'votos': votos
})
print(test_df.info())
```


```bash
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 134 entries, 0 to 133
Data columns (total 5 columns):
 #   Column     Non-Null Count  Dtype  
---  ------     --------------  -----  
 0   película   134 non-null    object 
 1   año        134 non-null    object 
 2   imdb       134 non-null    float64
 3   metascore  134 non-null    int64  
 4   votos      134 non-null    int64  
dtypes: float64(1), int64(2), object(2)
memory usage: 5.4+ KB
None
```

y ahora si reviso los primeros 5 elementos del DataFrame

```python
print(test_df.head(n=10))
```

```bash
                                película         año  imdb  metascore   votos
0                                Hablame   (I) (2022)   7.5         76   24315
1                                Babylon   (I) (2022)   7.1         60  140035
2                                      X  (II) (2022)   6.6         79  141075
3                       Un Vecino Gruñón       (2022)   7.5         51  119931
4             Avatar: El camino del agua       (2022)   7.6         67  451221
5                                 Batman       (2022)   7.8         72  723010
6                                Top Gun       (2022)   8.3         78  623797
7   Todo en todas partes al mismo tiempo       (2022)   7.8         81  473311
8                             La ballena       (2022)   7.7         60  171725
9                              Tren bala   (I) (2022)   7.3         49  380635
10                               El Menú       (2022)   7.2         71  343596
11                                 M3gan       (2022)   6.4         72  118519
12    El gato con botas: El último deseo       (2022)   7.9         73  151006
13                         Purple Hearts       (2022)   6.7         30   45567
14               No te preocupes, cariño   (I) (2022)   6.3         48  125158
15                                  Sisu       (2022)   6.9         70   52071
16                      Hasta los Huesos       (2022)   6.8         74   47994
17                     La ciudad perdida       (2022)   6.1         60  138711
18                                 Pearl       (2022)   7.0         76   68405
19           El Triángulo de la tristeza       (2022)   7.3         63  150714
```

¡Todo salió como se esperaba!

Como nota al margen, si ejecuta el código desde un país donde el inglés no es el idioma principal, es muy probable que obtenga algunos de los nombres de las películas traducidos al idioma principal de ese país.

Lo más probable es que esto suceda porque el servidor deduce su ubicación a partir de su dirección IP. Incluso si se encuentra en un país donde el inglés es el idioma principal, es posible que aún reciba contenido traducido. Esto puede suceder si estás usando una VPN mientras realizas las solicitudes `GET`.

Si lo tuyo es el inglés, pasa los siguientes valores al parámetro de `headers` de la función `get()`:

```python
headers = {"Accept-Language": "en-US, en;q=0.5"}
```

Esto comunicará al servidor algo como:

*“Quiero el contenido lingüístico en inglés americano (en-US). Si en-US no está disponible, entonces otros tipos de inglés (en) también estarían bien (pero no tanto como en-US)”.*

El parámetro `q` indica el grado en que preferimos un determinado idioma. Si no se especifica, el valor se establece en 1 de forma predeterminada, como en el caso de en-US. Puedes [leer más sobre esto aquí](https://www.rfc-editor.org/rfc/rfc9110.html#name-accept-language).

Ahora comencemos a crear el script para todas las páginas que queremos eliminar.


## El script de varias páginas.
Hacer el scraping para varias páginas es un poco más desafiante. Desarrollaremos nuestro script de una página haciendo tres cosas más:

1. Haciendo todas las peticiones que queramos desde dentro del bucle.
2. Controlar la velocidad del bucle para evitar bombardear el servidor con solicitudes.
3. Supervisión del bucle mientras se ejecuta.




### Cambiando los parámetros de las URLs
asdad

### Controlando la tasa de rastreo (crawl-rate)
asdas

### Monitoreando el bucle mientras continúa
asdad

### Juntando todo
asda

## Examinando los datos raspados
asdasda

## Limpiando los datos raspados
asdadsa

## Graficando y analizando las distribuciones
asdad

## Siguientes pasos
Hemos recorrido un largo camino desde solicitar el contenido de una sola página web hasta analizar las calificaciones de más de 2000 películas. Ahora debería saber cómo raspar muchas páginas web con la misma estructura HTML y URL.

Para aprovechar lo que hemos aprendido, estos son algunos de los siguientes pasos a considerar:

- Extraiga datos para diferentes intervalos de tiempo y página.
- Raspe datos adicionales sobre las películas.
- Encuentre un sitio web diferente para raspar algo que le interese. 
    - Por ejemplo, podría recopilar datos sobre [computadoras portátiles](https://listado.mercadolibre.com.co/port%C3%A1tiles#D[A:port%C3%A1tiles]) para ver cómo varían los precios con el tiempo.

---
excerpt: Un breve tutorial sobre web scraping usando beautiful soup. Es una traducción de un artículo de dataquest que ya no se encuentra disponible
---
pub_date: 2023-08-15
---
render_tdc: yes
